{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-b0d61715bdae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnetrc\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnetrc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0muser\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macct\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpasswd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnetrc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauthenticators\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"census\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m cen_con = psycopg2.connect(database = \"census\", user = user, password = passwd,\n\u001b[1;32m     30\u001b[0m                            host = \"localhost\", port = 5434)\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not iterable"
     ]
    }
   ],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import psycopg2\n",
    "\n",
    "from shapely.geometry import Point\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "import datetime\n",
    "import matplotlib.units as munits\n",
    "\n",
    "\n",
    "def date_format(ax):\n",
    "    \n",
    "    ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y'))\n",
    "    ax.xaxis.set_minor_formatter(mdates.DateFormatter('%b'))\n",
    "    ax.xaxis.set_major_locator(mdates.YearLocator())\n",
    "    ax.xaxis.set_minor_locator(mdates.MonthLocator())\n",
    "    ax.xaxis.set_tick_params(pad = 4, labelsize = 14, which = \"major\", rotation = 0)\n",
    "    ax.xaxis.set_tick_params(pad = 4, labelsize = 10, which = \"minor\", rotation = 0)\n",
    "    \n",
    "    plt.setp(ax.get_xticklabels(), rotation=0, ha=\"center\", rotation_mode=\"anchor\")\n",
    "\n",
    "    \n",
    "from netrc import netrc\n",
    "\n",
    "user, acct, passwd = netrc().authenticators(\"census\")\n",
    "cen_con = psycopg2.connect(database = \"census\", user = user, password = passwd,\n",
    "                           host = \"localhost\", port = 5434)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tract geometries from 2018 ACS.\n",
    "us4326 = gpd.read_postgis(\"SELECT geoid, ST_Transform(geomsimp, 4326) geom FROM census_tracts_2018;\",\n",
    "                          con = cen_con, geom_col = \"geom\", crs = \"EPSG:4326\")\n",
    "\n",
    "# Get basic demographics from 2017 ACS.\n",
    "prof17 = pd.read_sql(\"SELECT geoid, log_mhi, black, total_pop FROM acsprofile5y2017;\", con = cen_con)\n",
    "\n",
    "## Construct rank & categories for median household income.\n",
    "prof17[\"mhi_rank\"] = prof17.log_mhi.rank() / prof17.shape[0]\n",
    "prof17[\"mhi_class\"] = \"mid\"\n",
    "prof17.loc[prof17.mhi_rank < 0.25, \"mhi_class\"] = \"low\"\n",
    "prof17.loc[prof17.mhi_rank > 0.75, \"mhi_class\"] = \"high\"\n",
    "\n",
    "# Read in the SamKnows location data.\n",
    "sk = pd.read_excel(\"sk_sept2018.xlsx\", engine = \"openpyxl\")\n",
    "sk.rename(columns = {\"unit id\" : \"unit_id\"}, inplace = True)\n",
    "\n",
    "print(\"tract or blockgroup:\", sk.geog_type.isin([\"blockgroup\", \"tract\"]).mean())\n",
    "\n",
    "sk.query(\"(geog_type == 'blockgroup') | (geog_type == 'tract')\", inplace = True)\n",
    "\n",
    "## Transform this into a GeoDataFrame since the GEOIDs are busted.\n",
    "geo_sk = gpd.GeoSeries([Point(xy) for xy in sk[[\"longitude\", \"latitude\"]].values], \n",
    "                       index = sk.index, crs = \"EPSG:4326\")\n",
    "\n",
    "geo_sk = gpd.GeoDataFrame(data = sk, geometry = geo_sk, crs = \"EPSG:4326\")\n",
    "\n",
    "## Merge these together.\n",
    "sk_tr18 = gpd.sjoin(geo_sk, us4326, op = \"within\")[[\"unit_id\", \"geoid\"]]\n",
    "sk_tr18 = sk_tr18.sort_values(\"unit_id\").reset_index(drop = True)\n",
    "sk_tr18 = sk_tr18.sort_values(\"unit_id\")\n",
    "\n",
    "\n",
    "# Check that we're not losing data by merging 2018 and 2017 profile data.\n",
    "assert(pd.merge(sk_tr18, prof17).shape[0] == sk_tr18.shape[0])\n",
    "\n",
    "sk_tr18 = pd.merge(sk_tr18, prof17)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve and cache SamKnows data from the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "usage_sql = \"\"\"\n",
    "SELECT \n",
    "  unit_id, dtime::DATE dtime, \n",
    "  SUM(cust_wired_tx_bytes / 1e9) wired_tx_gb, \n",
    "  SUM(cust_wired_rx_bytes / 1e9) wired_rx_gb, \n",
    "  SUM(cust_wifi_tx_bytes  / 1e9) wifi_tx_gb, \n",
    "  SUM(cust_wifi_rx_bytes  / 1e9) wifi_rx_gb,\n",
    "  SUM(cust_wired_tx_bytes / 1e9 + cust_wifi_tx_bytes / 1e9) tx_gb, \n",
    "  SUM(cust_wired_rx_bytes / 1e9 + cust_wifi_rx_bytes / 1e9) rx_gb\n",
    "FROM datausage \n",
    "WHERE \n",
    "  dtime::DATE != '2020-02-07'\n",
    "GROUP BY unit_id, dtime::DATE\n",
    "HAVING\n",
    "  SUM(cust_wired_tx_bytes / 1e9 + cust_wifi_tx_bytes/ 1e9) < 1000\n",
    "ORDER BY unit_id, dtime::DATE\n",
    "\"\"\"\n",
    "\n",
    "speed_sql = \"\"\"\n",
    "SELECT\n",
    "  unit_id, dtime::DATE,\n",
    "  AVG(bytes_sec / 125000) speed\n",
    "FROM httpgetmt \n",
    "WHERE \n",
    "  dtime::DATE != '2020-02-07' AND\n",
    "  successes != 0 AND sequence < 5 AND\n",
    "  (target LIKE '%mlab%' OR target LIKE '%level3%') AND \n",
    "  address != '0'\n",
    "GROUP BY unit_id, dtime::DATE\n",
    "ORDER BY unit_id, dtime::DATE\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def retrieve_sk_data():\n",
    "    \n",
    "    user, acct, passwd = netrc().authenticators(\"sk\")\n",
    "    \n",
    "    sk_con = psycopg2.connect(database = \"sk\", user = user, password = passwd,\n",
    "                          host = \"localhost\", port = 5433)\n",
    "\n",
    "    usage = pd.read_sql(usage_sql, con = sk_con)\n",
    "    usage.to_csv(\"sk_usage.csv.gz\", index = False, header = True)\n",
    "    \n",
    "    httpgetmt = pd.read_sql(speed_sql, con = sk_con)\n",
    "    httpgetmt.to_csv(\"sk_httpgetmt.csv.gz\", index = False, header = True)\n",
    "\n",
    "# retrieve_sk_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Consumption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "usage = pd.read_csv(\"sk_usage.csv.gz\")\n",
    "usage[\"date\"] = pd.to_datetime(usage.dtime)\n",
    "usage = usage.merge(sk_tr18, on = \"unit_id\")\n",
    "\n",
    "usage_quantiles = usage.groupby([\"date\", \"mhi_class\"])[[\"tx_gb\", \"rx_gb\"]].quantile([0.25, 0.50, 0.75, 0.9])\n",
    "usage_quantiles = usage_quantiles.unstack().unstack().swaplevel(i = 1, j = 2, axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot defaults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = {\"low\" : \"#00FF88\", \"mid\" : \"#0088FF\", \"high\" : \"#FF00FF\"}\n",
    "ls = {0.25 : \":\", 0.5 : \"-\", 0.75 : \":\"}\n",
    "lw = {0.25 : 0.4, 0.5 : 1.5, 0.75 : 0.4, 0.9: 0.4}\n",
    "label = {\"mid\" : \"Middle\", \"low\" : \"Lower\", \"high\" : \"Upper\"}\n",
    "ylabel = {\"rx_gb\" : \"Received [GB/day]\", \"tx_gb\" : \"Transmitted [GB/day]\"}\n",
    "xlim = (\"2019-11-01\", \"2020-08-01\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize = (12, 3.5), sharex = True)\n",
    "\n",
    "for axi, v in zip(ax, [\"rx_gb\", \"tx_gb\"]):\n",
    "    for mhi in [\"low\", \"mid\", \"high\"]:\n",
    "        for q in [0.25, 0.5, 0.75]:\n",
    "\n",
    "            l = label[mhi] if (q == 0.5 and v == \"tx_gb\") else \"_\"\n",
    "\n",
    "            usage_quantiles[v][mhi][q].plot(color = colors[mhi], linewidth = lw[q],\n",
    "                                            ax = axi, label = l)\n",
    "            \n",
    "    axi.set_xlabel(\"\")\n",
    "    axi.set_ylabel(ylabel[v])\n",
    "    \n",
    "    axi.set_xlim(xlim)\n",
    "    \n",
    "    date_format(axi)\n",
    "        \n",
    "h, l = axi.get_legend_handles_labels()\n",
    "\n",
    "leg = axi.legend(h[::-1], l[::-1])\n",
    "leg.set_title(\"Income Level\", prop = {\"size\" : 15})\n",
    "leg.set_bbox_to_anchor((1.01, 0.5))\n",
    "\n",
    "ax[0].set_ylim(0, 10)\n",
    "ax[1].set_ylim(0, 1)\n",
    "\n",
    "fig.suptitle(\"Internet Consumption Quartiles by Tract Income Level\", fontsize = 15)\n",
    "\n",
    "fig.savefig(\"../figs/sk_consumption.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bandwidth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "httpgetmt = pd.read_csv(\"sk_httpgetmt.csv.gz\")\n",
    "httpgetmt[\"date\"]  = pd.to_datetime(httpgetmt.dtime)\n",
    "httpgetmt = httpgetmt.merge(sk_tr18, on = \"unit_id\")\n",
    "\n",
    "speed_quantiles = httpgetmt.groupby([\"date\", \"mhi_class\"]).speed.quantile([0.25, 0.50, 0.75, 0.9])\n",
    "speed_quantiles = speed_quantiles.unstack().unstack().swaplevel(i = 0, j = 1, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (5.5, 3.5))\n",
    "\n",
    "for mhi in [\"low\", \"mid\", \"high\"]:\n",
    "    for q in [0.25, 0.5, 0.75]:\n",
    "\n",
    "        l = label[mhi] if (q == 0.5) else \"_\"\n",
    "\n",
    "        speed_quantiles[mhi][q].plot(color = colors[mhi], linewidth = lw[q],\n",
    "                                     ax = ax, label = l)\n",
    "\n",
    "ax.set_xlabel(\"\")\n",
    "ax.set_ylabel(\"Speed [Mbytes / sec]\")\n",
    "\n",
    "ax.set_xlim(xlim)\n",
    "\n",
    "date_format(ax)\n",
    "        \n",
    "h, l = ax.get_legend_handles_labels()\n",
    "\n",
    "leg = ax.legend(h[::-1], l[::-1])\n",
    "leg.set_title(\"Income Level\", prop = {\"size\" : 15})\n",
    "leg.set_bbox_to_anchor((1.01, 0.5))\n",
    "\n",
    "fig.suptitle(\"Bandwidth Quartiles by Tract Income Level\", fontsize = 15)\n",
    "\n",
    "fig.savefig(\"../figs/sk_bandwidth.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'geo_sk' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-2546bc024c9c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgeo_sk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'geo_sk' is not defined"
     ]
    }
   ],
   "source": [
    "create table httpgetspeedweekly as select unit_id, avg(bytes_sec) as speed, date_trunc('week',dtime) as date from httpget group by unit_id, date;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
